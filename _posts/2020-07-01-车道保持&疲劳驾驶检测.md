---
title: 车道保持&疲劳驾驶检测
tags: 机器学习
---

[toc]

[github](https://github.com/verylazycat/DriverAssistanceSystem)

> 有问题可私信我

# 功能模块

- 车道保持
  - 车道线识别
  - 航向判断

- 驾驶员行为及状态检测
  - 疲劳检测

# 车道线&车况识别总体流程图

# ![detect](/img/detect.png)

对输入的每一帧图像主要有如下处理：

1.车道线识别：
	1.1.降噪
	1.2.边缘检测
	1.3.ROI处理
	1.4.霍夫线获取
	1.5.路线获取
	1.6.渲染

2.车况识别：
	2.1.加载yolo网络
	2.2.前向传播
	3.3.渲染

# 车道线识别主要操作

# ![车道线处理](/img/车道线处理.png)

# 方向判断逻辑

# ![方向判断](/img/方向判断.png)

获得道路线后，即我们获取了两个方程:
$$
y1 = a1x1 + b1\\
y2 = a2x2 + b2
$$
计算两直线交点(x0,y0),即左图所提的消失点；
此外，我们已知图像水平方向中心直线：x；

由此，我们有如下判断依据：

- x0 > x + thr_vp :右转
- x0 < x - thr_vp:左转
- x0 >= (x - thr_vp) && x0 <= (x + thr_vp)：直线

>注：thr_vp为调整参数，根据实际情况调试

![测试](/img/测试.png)

# 车况识别

基于深度学习的目标检测与识别算法大致分为以下三大类:
1.基于区域建议的目标检测与识别算法，如R-CNN, Fast-R-CNN, Faster-R-CNN;
2.基于回归的目标检测与识别算法，如YOLO, SSD;
3.基于搜索的目标检测与识别算法，如基于视觉注意的AttentionNet；

----

此处识别采用YOLO算法,其优点如下：
1.速度非常快。在Titan X GPU上的速度是45 fps，加速版的YOLO差不多是150fps；
2.YOLO是基于图像的全局信息进行预测的；
3.泛化能力强；
4.准确率高；

- 具体算法参考yolo论文
- 训练参考[DarkNet](https://pjreddie.com/darknet/yolo/)

> 注：由于笔记本计算能力有限，此处采用开源coco数据集训练的yolo模型，支持80个分类识别，具体分类参考配置文件

## 快速体验yolo

- 安装

```bash
git clone https://github.com/pjreddie/darknet.git
cd darknet
make
```

输出如下内容即安装成功

```bash
mkdir -p obj
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
.....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast -lm....
```

> 注意:根据自己环境调整 Makefile ,尤其是 GPU , CUDNN , OPENCV

- 下载weights文件

```bash
wget https://pjreddie.com/media/files/yolov .weights
```

- 测试

```bash
./darknet detect cfg/yolov .cfg yolov .weights data/dog.jpg
```

# 驾驶员行为及状态检测

# ![驾驶员行为及状态检测](/img/驾驶员行为及状态检测.png)

关键操作有如下：

1.保存驾驶人员启动程序时的状态数据

2.判断是否无人驾驶

3.依据记录的状态数据判断当前技术人员状态是否异常

# 状态特征判断依据

有如下内容需要了解:

1.“眼睛纵横比”（EAR）
我们可以应用面部标志检测来定位脸部的重要区域，包括眼睛，眉毛，鼻子，耳朵和嘴巴

2.EAR计算公式
$$
EAR = (||p_{2} - p_{6}||+||p_{3}-p_{5}||)/(2||p_{1} -p_{4}||)
$$
![eyeEar](/img/eyeEar.png)

> 详细内容参考Soukupová和Čech在其2016年的论文Real-Time Eye Blink Detection using Facial Landmarks

## Landmark算法

点标记》一文中有效果和标定点序号的示意图。今后可采用landmark中的点提取眼睛区域、嘴巴区
域用于疲劳检测,提取鼻子等部分可用于3D姿态估计。
Dlib库使用《One Millisecond Face Alignment with an Ensemble of Regression Trees》CVPR2014
中提及的算法:ERT(ensemble of regression trees)级联回归,即基于梯度提高学习的回归树方法。
该算法使用级联回归因子,首先需要使用一系列标定好的人脸图片作为训练集,然后会生成一个模型。
使用基于特征选择的相关性方法把目标输出投影到一个随机方向w上,并且选择一对特征(u,v),使
得Ii(u )-Ii(v )与被投影的目标wTri在训练数据上拥有最高的样本相关性。
当获得一张图片后,算法会生成一个initial shape就是首先估计一个大致的特征点位置,然后采用
gradient boosting算法减小initial shape 和 ground truth 的平方误差总和。用最小二乘法来最小化误
差,得到每一级的级联回归因子。核心公式如下:
$$
\hat{S}^{t+1} = \hat{S}+r_{t}(I,\hat{t}^{t})
$$
示当前级的回归器regressor。回归器的输入参数为图像I和上一级回归器更新后的shape,采用的特征可
以是灰度值或者其它。每个回归器由很多棵树(tree)组成,每棵树参数是根据current shape和ground
truth的坐标差和随机挑选的像素对训练得到的。

与LBF不同,ERT是在学习Tree的过程中,直接将shape的更新值ΔS存入叶子结点leaf node.初始位
置S在通过所有学习到的Tree后,meanshape加上所有经过的叶子结点的ΔS,即可得到最终的人脸关
键点位置。

# EAR参考意义

“眼睛纵横比”(EAR):我们可以应用面部标志检测来定位脸部的重要区域,包括眼睛,眉毛,鼻子,
耳朵和嘴巴.

1.其中p1...p6是2D面部地标位置;
2.方程的分子是计算垂直眼睛标志之间的距离，而分母是计算水平眼睛标志之间的距离，因为只有一组水平点，但是有两组垂直点，所以进行加权分母

![EAR](/img/EAR.png)

> 当人眼闭眼时，EAR急剧减小，我们利用这一点去检测人眼闭眼状态

![EARTEST](/img/EARTEST.png)

# 源码

- FatigueDrivingDetection

> main

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-05 14:56:20 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:39:19
 */
#include <main.h>
#include <render_face.h>
#include <Compute.h>
#include <BuzzerControl.h>
#include <fatigueDetection.h>
#include <getTime.h>
int main()
{
	//判断的基础信息
	double LeftEyeBase,RightEyeBase,InnerLipBase;
	//标志位,用于第一次录入基础信息
	int Base = 1;
	//记录哈欠次数
	int innerLipCounts = 0;
	//记录眯眼次数
	int squintingCounts = 0;
	try
	{
		//读取摄像头
		cv::VideoCapture cap(0);
		// 窗体大小设置,看需求
		//cap.set(CV_CAP_PROP_FRAME_WIDTH, 640);  
		//cap.set(CV_CAP_PROP_FRAME_HEIGHT, 480);  
		//模型加载 
		frontal_face_detector detector = get_frontal_face_detector();
		shape_predictor pose_model;
		deserialize(datPath) >> pose_model;
 
		int count = 0;
		std::vector<dlib::rectangle> faces;

		while (1)
		{
			cv::Mat img, img_small;
			cap >> img;
			//文字
			cv::putText(img,"s:save,q:quit",cv::Point(img.rows/2,img.cols/2),FONT_HERSHEY_SIMPLEX,2,Scalar(0,0,255),1,8,false);
			cv::resize(img, img_small, cv::Size(), 1.0 / RATIO, 1.0 / RATIO);
 
			cv_image<bgr_pixel> cimg(img);
			cv_image<bgr_pixel> cimg_small(img_small);
 
			//人脸检测   
			if (count++ % SKIP_FRAMES == 0) {
				faces = detector(cimg_small);
			}
			cout << "检测人数:" << faces.size() << endl;
			//无人状态
			if(faces.empty())
			{
				cout  << "\033[31m警告:无人状态\033[0m"<< endl;
				//蜂鸣器功能,后续添加
				// BuzzerControl();
				getCurrentTime();
			}

			// 关键点检测  
			std::vector<full_object_detection> shapes;
			for (unsigned long i = 0; i < faces.size(); ++i) 
			{
				dlib::rectangle r(
					(long)(faces[i].left() * RATIO),
					(long)(faces[i].top() * RATIO),
					(long)(faces[i].right() * RATIO),
					(long)(faces[i].bottom() * RATIO)
				);
				// 关键点保存
				full_object_detection shape = pose_model(cimg, r);
				shapes.push_back(shape);
 
				//渲染画线
				render_face(img, shape);
				double rightEye = RightEyeCompute(img,shape);
				double leftEye = LeftEyeCompute(img,shape);
				double innerLip = InnerLipCompute(img,shape);
				cout<<"-------------"<<endl;

				//第一次识别信息导入,以此为后续判断的标注
				//RightEyeBase,LeftEyeBase,innerLipBase
				if(Base)
				{
					RightEyeBase = rightEye;
					LeftEyeBase = leftEye;
					InnerLipBase = innerLip;
					//退出信息录入,避免后续覆盖
					Base--;
					cout<<"用户数据录入成功>>>初始化成功!"<<endl;
				}
				int temp = fatigueDetection(LeftEyeBase,leftEye,RightEyeBase,rightEye,InnerLipBase,innerLip,innerLipCounts,squintingCounts);
				innerLipCounts += temp;
				squintingCounts += temp;
				//疲劳驾驶
				// innerLipCounts 哈欠次数 需要实际调试确定临界点
				if(innerLipCounts >= 50)
				{
					//红色打印
					cout  << "\033[31m警告:疲劳驾驶\033[0m"<< endl;	
					getCurrentTime();	
				}
				// squintingCounts 眯眼次数
				if(squintingCounts >= 50)
				{
					//红色打印
					cout  << "\033[31m警告:疲劳驾驶\033[0m"<< endl;	
					getCurrentTime();
				}
				//----------------------------------------------------
			}
			// std::cout << "count:" << count << std::endl;
			if (img.empty())
			{
				cerr<<"img is mepty!"<<endl;
				getCurrentTime();
				break;
			}
			imshow("Frame", img);
			// Q q退出
			char c = (char)waitKey(25);
			if (c == 'Q' || c == 'q')
			{
				cout<<"退出成功"<<endl;
				getCurrentTime();
				break;
			}
			if(c == 's'||c == 'S')
			{
				cv::imwrite("../img/img.png",img);
				cout<<"保存成功"<<endl;
				getCurrentTime();
			}
		}
	}
	catch (serialization_error& e)
	{
		cout << "模型下载链接 " << endl;
		cout << "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" << endl;
		cout << endl << e.what() << endl;
		getCurrentTime();
	}
	catch (exception& e)
	{
		cout << e.what() << endl;
		getCurrentTime();
	}
	return 0;
}
```

> BuzzerControl.h

```c
/*
 * @Author: verylazycat 
 * @Date: 2020-02-07 12:15:16 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:18:52
 */
// 蜂鸣器控制
#include <main.h>
int BuzzerControl()
{
    return 0;
}
```

> Compute.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 12:29:42 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:19:28
 */
#include <main.h>
#include <cmath>
// 欧式距离计算
double PointsCompute(int x1,int y1,int x2,int y2)
{
    double results = 0;
    results = sqrt(pow(x1-x2,2) + pow(y1 - y2,2));
    return results;
}
// Right Eye:42~47
double RightEyeCompute(cv::Mat &img,const dlib::full_object_detection& d)
{
    double result = 0;
    std::vector<cv::Point> points;
    for(int i = 42;i <=47;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[5].x,points[5].y) + PointsCompute(points[2].x,points[2].y,points[4].x,points[4].y))/(2*PointsCompute(points[0].x,points[0].y,points[3].x,points[3].y)); 
    cout<<"右眼高宽比例:";
    cout<<result<<endl;
    return result;
}
//Left Eye:36 ~ 41
double LeftEyeCompute(cv::Mat &img,const dlib::full_object_detection& d)
{
    double result = 0;
    std::vector<cv::Point> points;
    for(int i = 36;i <=41;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[5].x,points[5].y) + PointsCompute(points[2].x,points[2].y,points[4].x,points[4].y))/(2*PointsCompute(points[0].x,points[0].y,points[3].x,points[3].y)); 
    cout<<"左眼高宽比例:";
    cout<<result<<endl;
    return result;
}
//inner lip :60 ~ 67
double InnerLipCompute(cv::Mat &img,const dlib::full_object_detection& d)
{
    double result = 0;
    std::vector<cv::Point> points;
    for(int i = 60;i <=67;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[7].x,points[7].y) + PointsCompute(points[3].x,points[3].y,points[5].x,points[5].y))/(2*PointsCompute(points[0].x,points[0].y,points[4].x,points[4].y)); 
    cout<<"内嘴唇高宽比例:";
    cout<<result<<endl;
    return result;
}
```

> fatigueDetection.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-09 12:41:21 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:41:51
 */
//警告状态
#include <main.h>
int fatigueDetection(double leftEyeBase,double leftEye,double rightEyeBase,double rightEye,double innerLipBase,double innerLip,int innerLipCounts,int squintingCounts)
{
    //当内嘴唇高宽比例大于基础高宽比0.,定义位打哈欠
    if(innerLip - innerLipBase >= 0.3)
    {
        //绿色打印
        cout  << "\033[32m警告:哈欠:\033[0m"<<innerLipCounts<< endl;
        //计数
        return 1;
    }
    if(leftEyeBase - leftEye >=0.1 || rightEyeBase - rightEye >= 0.1)
    {
        //绿色打印
        cout  << "\033[32m警告:眯眼:\033[0m"<<squintingCounts<< endl;
        //计数
        return 1;
    }
    if((leftEye + rightEye)/2 < 0.2)
    {
        // 绿色打印
        cout  << "\033[32m警告:闭眼\033[0m"<< endl;	
    }
    return 0;
}
```

> getTime.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-09 13:27:35 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:37:06
 */
#include <main.h>
void getCurrentTime()
{
    time_t rawtime;
    struct tm *ptminfo;
 
    time(&rawtime);
    ptminfo = localtime(&rawtime);
    printf("current: %02d-%02d-%02d %02d:%02d:%02d\n",
            ptminfo->tm_year + 1900, ptminfo->tm_mon + 1, ptminfo->tm_mday,
            ptminfo->tm_hour, ptminfo->tm_min, ptminfo->tm_sec);
}
```

> main.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 11:26:56 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:36:59
 */
#ifndef __BUILD__
#define __BUILD__
#include <dlib/opencv.h>  
#include <opencv2/opencv.hpp>  
#include <dlib/image_processing/frontal_face_detector.h>  
#include <dlib/image_processing/render_face_detections.h>  
#include <dlib/image_processing.h>  
#include <dlib/gui_widgets.h>  
#include "opencv2/opencv.hpp"
#include <iostream>
#include <ctime>
#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <sys/ioctl.h>

using namespace dlib;
using namespace std;
using namespace cv;

#define RATIO 4  
#define SKIP_FRAMES 2 

cv::String datPath = "../config/shape_predictor_68_face_landmarks.dat";

#endif
```

> render_face.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 11:57:30 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:19:01
 */
#include <main.h>
// 画线 
void draw_polyline(cv::Mat &img, const dlib::full_object_detection& d, const int start, const int end, bool isClosed = false)
{
	std::vector <cv::Point> points;
	for (int i = start; i <= end; ++i)
	{
		points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
	}
	cv::polylines(img, points, isClosed, cv::Scalar(255, 0, 0), 2, 16);
}
// 渲染 
void render_face(cv::Mat &img, const dlib::full_object_detection& d)
{
	DLIB_CASSERT
	(
		d.num_parts() == 68,
		"\n\t Invalid inputs were given to this function. "
		<< "\n\t d.num_parts():  " << d.num_parts()
	);
 
	draw_polyline(img, d, 0, 16);           // Jaw line
	draw_polyline(img, d, 17, 21);          // Left eyebrow
	draw_polyline(img, d, 22, 26);          // Right eyebrow
	draw_polyline(img, d, 27, 30);          // Nose bridge
	draw_polyline(img, d, 30, 35, true);    // Lower nose
	draw_polyline(img, d, 36, 41, true);    // Left eye
	draw_polyline(img, d, 42, 47, true);    // Right Eye
	draw_polyline(img, d, 48, 59, true);    // Outer lip
	draw_polyline(img, d, 60, 67, true);    // Inner lip
 
}
```

> CMakeLists.txt

```makefile
#SET CMAKE VERSION
CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
# 优化
# SET(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -O2")
SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Ofast")
#SET PROJECT NAME
SET(PROJECT_NAME FatigueDrivingDetection)
#BUILD PROJECT NAME
PROJECT(${PROJECT_NAME})
#FIND OPENCV 
FIND_PACKAGE(OpenCV REQUIRED)
INCLUDE_DIRECTORIES(${OpenCV_INCLUDE_DIRS})
#FIND DLIB
FIND_PACKAGE(dlib REQUIRED)
INCLUDE_DIRECTORIES(${dlib_INCLUDE_DIRS})
#PRINT STATUS
MESSAGE(STATUS "Project: ${PROJECT_NAME}")
MESSAGE(STATUS "------------------------------------------------------")
MESSAGE(STATUS "OpenCV library status:")
MESSAGE(STATUS "version: ${OpenCV_VERSION}")
MESSAGE(STATUS "libraries: ${OpenCV_LIBS}")
MESSAGE(STATUS "include path: ${OpenCV_INCLUDE_DIRS}")
MESSAGE(STATUS "------------------------------------------------------")
MESSAGE(STATUS "DLIB library status:")
MESSAGE(STATUS "version: ${dlib_VERSION}")
MESSAGE(STATUS "libraries: ${dlib_LIBS}")
MESSAGE(STATUS "include path: ${dlib_INCLUDE_DIRS}")
MESSAGE(STATUS "------------------------------------------------------")
#GET CODE FROM SRC FOLDER
AUX_SOURCE_DIRECTORY(src DIR_SRCS)
include_directories(include)
MESSAGE(STATUS "Src file: ${DIR_SRCS}")
#编译可执行程序
ADD_EXECUTABLE(${PROJECT_NAME} ${DIR_SRCS})
#添加链接库
TARGET_LINK_LIBRARIES(${PROJECT_NAME} ${OpenCV_LIBS} ${dlib_LIBRARIES})
```

## lane_car_detect

> main.cpp

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 12:39:24 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-18 13:12:06
 */
#include "yolo_car_detect.h"
#include "lane_detect.h"
#include <iostream>
#include <stdlib.h>
#include <stdio.h>
#include <error.h>

// 摄像头调用
// #define __USE__CAP_0__

//视频测试
#define __USE__VIDEO__

int main(int argc ,char *argv[]) 
{
	
	#ifdef  __USE__CAP_0__
	//摄像头测试
	cv::VideoCapture cap(0);
	#endif

	#ifdef  __USE__VIDEO__
	cv::VideoCapture cap("../video/test.mp4");
	#endif
	
	if (!cap.isOpened())
		return -1;
	//config检测
	configFileDect;
	//导入网络
    Net net = readNetFromDarknet(modelConfiguration, modelWeights);
    net.setPreferableBackend(DNN_BACKEND_OPENCV);
    net.setPreferableTarget(DNN_TARGET_CPU);
    Mat frame, blob;
	//lane检测
	LaneDetector lanedetector; 
	// frame处理
	while (i < 540) {
		//frame为空
		if (!cap.read(frame))
			break;
		//按照预先设定的参数初始化frame
        blobFromImage(frame, blob, 1/255.0, cvSize(inpWidth, inpHeight), Scalar(0,0,0), true, false);
        //将预处理后的frame输入网络
        net.setInput(blob);
        // 前向传播获取outs
        vector<Mat> outs;
        net.forward(outs, getOutputsNames(net));
        // 值信度抑制
		postprocess(frame, outs);
		//time
        vector<double> layersTimes;
        double f = getTickFrequency() / 1000;
        double t = net.getPerfProfile(layersTimes) / f;
        string label = format("Inference time for a frame : %.2f ms", t);
        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255));
		// 降噪
		img_denoise = lanedetector.deNoise(frame);
		//边缘检测
		img_edges = lanedetector.edgeDetector(img_denoise);
		// ROI
		img_mask = lanedetector.mask(img_edges);
		//霍夫线获取
		lines = lanedetector.houghLines(img_mask);
		if (!lines.empty())
		{
			//区分左右
			left_right_lines = lanedetector.lineSeparation(lines, img_edges);
			//过滤
			lane = lanedetector.regression(left_right_lines, frame);
			//消失点预测方向
			turn = lanedetector.predictTurn();
			//航向输出
			cout<<turn<<endl;
			//渲染
			flag_plot = lanedetector.plotLane(frame, lane, turn);
			cv::waitKey(25);
		}
		else {
			flag_plot = -1;
		}
	}
	return flag_plot;
}
```

> lane_detect.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 18:45:15 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-17 18:46:14
 */
#include <string>
#include <opencv2/opencv.hpp>
class LaneDetector 
{
private:
	double img_size;
	double img_center;
    // 左边界
	bool left_flag = false;  
    // 右边界
	bool right_flag = false;
    // 车道线方程  
    // y = m*x + b
	cv::Point right_b;  
	double right_m;  
	cv::Point left_b; 
	double left_m;  

public:
    //高斯模糊
	cv::Mat deNoise(cv::Mat inputImage);  
    // 边缘提取
	cv::Mat edgeDetector(cv::Mat img_noise);
    // ROI  
	cv::Mat mask(cv::Mat img_edges);  
    // 霍夫线检测
	std::vector<cv::Vec4i> houghLines(cv::Mat img_mask);  
    //路线提取
	std::vector<std::vector<cv::Vec4i> > lineSeparation(std::vector<cv::Vec4i> lines, cv::Mat img_edges);  
    //车道线获取,一条
	std::vector<cv::Point> regression(std::vector<std::vector<cv::Vec4i> > left_right_lines, cv::Mat inputImage);  
    // 转向决策，消失点决策
	std::string predictTurn();  
    // 渲染绘画
	int plotLane(cv::Mat inputImage, std::vector<cv::Point> lane, std::string turn);  
};

cv::Mat LaneDetector::deNoise(cv::Mat inputImage) {
	cv::Mat output;
	cv::GaussianBlur(inputImage, output, cv::Size(3, 3), 0, 0);
	return output;
}

cv::Mat LaneDetector::edgeDetector(cv::Mat img_noise) {
	cv::Mat output;
	cv::Mat kernel;
	cv::Point anchor;

	//灰度化
	cv::cvtColor(img_noise, output, cv::COLOR_RGB2GRAY);
	// 二值化
	cv::threshold(output, output, 140, 255, cv::THRESH_BINARY);

    // 偏离警告
	anchor = cv::Point(-1, -1);
	kernel = cv::Mat(1, 3, CV_32F);
	kernel.at<float>(0, 0) = -1;
	kernel.at<float>(0, 1) = 0;
	kernel.at<float>(0, 2) = 1;

	//边缘提取
	cv::filter2D(output, output, -1, kernel, anchor, 0, cv::BORDER_DEFAULT);
	// cv::imshow("output", output);
	return output;
}

cv::Mat LaneDetector::mask(cv::Mat img_edges) {
	cv::Mat output;
    // 创建mask
	cv::Mat mask = cv::Mat::zeros(img_edges.size(), img_edges.type());
	// 定位点
    cv::Point pts[4] = {
		cv::Point(210, 720),
		cv::Point(550, 450),
		cv::Point(717, 450),
		cv::Point(1280, 720)
	};
    // 区域填充
	cv::fillConvexPoly(mask, pts, 4, cv::Scalar(255, 0, 0));
	//图像和mask相乘输出
	cv::bitwise_and(img_edges, mask, output);
	return output;
}

//霍夫直线检测
std::vector<cv::Vec4i> LaneDetector::houghLines(cv::Mat img_mask) {
	std::vector<cv::Vec4i> line;
	HoughLinesP(img_mask, line, 1, CV_PI / 180, 20, 20, 30);

	return line;
}
//路线提取
//过滤line
//左右两条line
std::vector<std::vector<cv::Vec4i> > LaneDetector::lineSeparation(std::vector<cv::Vec4i> lines, cv::Mat img_edges) {
	std::vector<std::vector<cv::Vec4i> > output(2);
	size_t j = 0;
	cv::Point ini;
	cv::Point fini;
    //斜率限制阈值
	double slope_thresh = 0.3;
	std::vector<double> slopes;
	std::vector<cv::Vec4i> selected_lines;
	std::vector<cv::Vec4i> right_lines, left_lines;

	// 斜率计算
	for (auto i : lines) {
		ini = cv::Point(i[0], i[1]);
		fini = cv::Point(i[2], i[3]);

		// m = (y1 - y0)/(x1 - x0)
		double slope = (static_cast<double>(fini.y) - static_cast<double>(ini.y)) / (static_cast<double>(fini.x) - static_cast<double>(ini.x) + 0.00001);

		//如果小于限制阈值，则去除
        //保存大于限制阈值的线
		if (std::abs(slope) > slope_thresh) {
			slopes.push_back(slope);
			selected_lines.push_back(i);
		}
	}

	// 区分左右线
	img_center = static_cast<double>((img_edges.cols / 2));
	while (j < selected_lines.size()) {
		ini = cv::Point(selected_lines[j][0], selected_lines[j][1]);
		fini = cv::Point(selected_lines[j][2], selected_lines[j][3]);

		// 如果斜率大于０且fini.x和fini大于图像中心点,则判断为左侧,反之右侧
		if (slopes[j] > 0 && fini.x > img_center && ini.x > img_center) {
			right_lines.push_back(selected_lines[j]);
			right_flag = true;
		}
		else if (slopes[j] < 0 && fini.x < img_center && ini.x < img_center) {
			left_lines.push_back(selected_lines[j]);
			left_flag = true;
		}
		j++;
	}

	output[0] = right_lines;
	output[1] = left_lines;

	return output;
}

//最终车道线选择
std::vector<cv::Point> LaneDetector::regression(std::vector<std::vector<cv::Vec4i> > left_right_lines, cv::Mat inputImage) {
	std::vector<cv::Point> output(4);
	cv::Point ini;
	cv::Point fini;
	cv::Point ini2;
	cv::Point fini2;
	cv::Vec4d right_line;
	cv::Vec4d left_line;
	std::vector<cv::Point> right_pts;
	std::vector<cv::Point> left_pts;

	// 检测到右侧线，则把点给连上
	if (right_flag == true) {
		for (auto i : left_right_lines[0]) {
			ini = cv::Point(i[0], i[1]);
			fini = cv::Point(i[2], i[3]);

			right_pts.push_back(ini);
			right_pts.push_back(fini);
		}

		if (right_pts.size() > 0) {
			//拟合
			cv::fitLine(right_pts, right_line, CV_DIST_L2, 0, 0.01, 0.01);
			right_m = right_line[1] / right_line[0];
			right_b = cv::Point(right_line[2], right_line[3]);
		}
	}

	// 检测到左侧线，则把点给连上
	if (left_flag == true) {
		for (auto j : left_right_lines[1]) {
			ini2 = cv::Point(j[0], j[1]);
			fini2 = cv::Point(j[2], j[3]);

			left_pts.push_back(ini2);
			left_pts.push_back(fini2);
		}

		if (left_pts.size() > 0) {
			//拟合
			cv::fitLine(left_pts, left_line, CV_DIST_L2, 0, 0.01, 0.01);
			left_m = left_line[1] / left_line[0];
			left_b = cv::Point(left_line[2], left_line[3]);
		}
	}

	// 通过直线方程获得点
	int ini_y = inputImage.rows;
	int fin_y = 470;

	double right_ini_x = ((ini_y - right_b.y) / right_m) + right_b.x;
	double right_fin_x = ((fin_y - right_b.y) / right_m) + right_b.x;

	double left_ini_x = ((ini_y - left_b.y) / left_m) + left_b.x;
	double left_fin_x = ((fin_y - left_b.y) / left_m) + left_b.x;

	output[0] = cv::Point(right_ini_x, ini_y);
	output[1] = cv::Point(right_fin_x, fin_y);
	output[2] = cv::Point(left_ini_x, ini_y);
	output[3] = cv::Point(left_fin_x, fin_y);

	return output;
}


std::string LaneDetector::predictTurn() {
	std::string output;
	double vanish_x;
	double thr_vp = 10;

	//消失点:两直线交点
	vanish_x = static_cast<double>(((right_m*right_b.x) - (left_m*left_b.x) - right_b.y + left_b.y) / (right_m - left_m));

	//决策
	if (vanish_x < (img_center - thr_vp))
		output = "Left Turn";
	else if (vanish_x >(img_center + thr_vp))
		output = "Right Turn";
	else if (vanish_x >= (img_center - thr_vp) && vanish_x <= (img_center + thr_vp))
		output = "Straight";

	return output;
}

int LaneDetector::plotLane(cv::Mat inputImage, std::vector<cv::Point> lane, std::string turn) 
{
	std::vector<cv::Point> poly_points;
	cv::Mat output;

	//渲染内部
	inputImage.copyTo(output);
	poly_points.push_back(lane[2]);
	poly_points.push_back(lane[0]);
	poly_points.push_back(lane[1]);
	poly_points.push_back(lane[3]);
	cv::fillConvexPoly(output, poly_points, cv::Scalar(0, 0, 255), CV_AA, 0);
	cv::addWeighted(output, 0.3, inputImage, 1.0 - 0.3, 0, inputImage);

	//划线
	cv::line(inputImage, lane[0], lane[1], cv::Scalar(0, 255, 255), 5, CV_AA);
	cv::line(inputImage, lane[2], lane[3], cv::Scalar(0, 255, 255), 5, CV_AA);

	// 决策信息
	cv::putText(inputImage, turn, cv::Point(50, 90), cv::FONT_HERSHEY_COMPLEX_SMALL, 3, cvScalar(0, 255, 0), 1, CV_AA);

	cv::namedWindow("Lane", CV_WINDOW_AUTOSIZE);
	cv::imshow("Lane", inputImage);
	return 0;
}
```

> yolo_car_detect.h

```c++
/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 14:28:03 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-18 12:12:02
 */
#include <opencv2/dnn.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <fstream>
#include <sstream>
#include <vector>

using namespace cv;
using namespace dnn;
using namespace std;

//置信度
float confThreshold = 0.5;
float nmsThreshold = 0.4;

//图片输入尺寸
//参看cfg配置文件
int inpWidth = 416;  
int inpHeight = 416; 
//配置文件
const string classesFile = "../config/coco.names";
const string modelConfiguration = "../config/yolov3-tiny.cfg";
const string modelWeights = "../config/yolov3-tiny.weights";
//测试视频
cv::Mat img_denoise;
cv::Mat img_edges;
cv::Mat img_mask;
std::vector<cv::Vec4i> lines;
std::vector<std::vector<cv::Vec4i> > left_right_lines;
std::vector<cv::Point> lane;
std::string turn;
int flag_plot = -1;
int i = 0;
vector<string> classes;
// 删除置信度低的图片
void postprocess(Mat& frame, const vector<Mat>& out);

//画预测框
void drawPred(int classId, float conf, int left, int top, int right, int bottom, Mat& frame);

//获取分类
vector<String> getOutputsNames(const Net& net);

//config检测
size_t configFileDect()
{
	if(classesFile == NULL)
	{
		fprintf(stdout,"classesFile is NULL\n");
		return 1;
	}
	if(modelConfiguration == NULL)
	{
		perror("modelConfiguration");
		return 1;
	}
	if(modelWeights == NULL)
	{
		perror("modelWeights");
		return 1;
	}
}


//抑制低置信度
void postprocess(Mat& frame, const vector<Mat>& outs)
{
    vector<int> classIds;
    vector<float> confidences;
    vector<Rect> boxes;
    // 遍历每一个box
    for (size_t i = 0; i < outs.size(); ++i)
    {
        float* data = (float*)outs[i].data;
        for (int j = 0; j < outs[i].rows; ++j, data += outs[i].cols)
        {
            Mat scores = outs[i].row(j).colRange(5, outs[i].cols);
            Point classIdPoint;
            double confidence;
            //获取score最大和最小值
            minMaxLoc(scores, 0, &confidence, 0, &classIdPoint);
            if (confidence > confThreshold)
            {
                int centerX = (int)(data[0] * frame.cols);
                int centerY = (int)(data[1] * frame.rows);
                int width = (int)(data[2] * frame.cols);
                int height = (int)(data[3] * frame.rows);
                int left = centerX - width / 2;
                int top = centerY - height / 2;
                
                classIds.push_back(classIdPoint.x);
                confidences.push_back((float)confidence);
                boxes.push_back(Rect(left, top, width, height));
            }
        }
    }
    
    vector<int> indices;
    NMSBoxes(boxes, confidences, confThreshold, nmsThreshold, indices);
    for (size_t i = 0; i < indices.size(); ++i)
    {
        int idx = indices[i];
        Rect box = boxes[idx];
        drawPred(classIds[idx], confidences[idx], box.x, box.y,
                 box.x + box.width, box.y + box.height, frame);
    }
}

//绘画渲染
void drawPred(int classId, float conf, int left, int top, int right, int bottom, Mat& frame)
{
    //矩形框
    rectangle(frame, Point(left, top), Point(right, bottom), Scalar(0, 255, 0), 3);
    
    //获取name和置信度
    string label = format("%.2f", conf);
    if (!classes.empty())
    {
        CV_Assert(classId < (int)classes.size());
        label = classes[classId] + ":" + label;
    }
    //说明
    int baseLine;
    Size labelSize = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseLine);
    top = max(top, labelSize.height);
    rectangle(frame, Point(left, top - round(1.5*labelSize.height)), Point(left + round(1.5*labelSize.width), top + baseLine), Scalar(255, 255, 255), FILLED);
    putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.75, Scalar(0,0,0),1);
}
//获取name
vector<String> getOutputsNames(const Net& net)
{
    static vector<String> names;
    if (names.empty())
    {
        vector<int> outLayers = net.getUnconnectedOutLayers();
        //获取所有name
        vector<String> layersNames = net.getLayerNames();
        //获取当前的name
        names.resize(outLayers.size());
        for (size_t i = 0; i < outLayers.size(); ++i)
        names[i] = layersNames[outLayers[i] - 1];
    }
    return names;
}
```

# 安装使用

## opencv配置

> 建议使用3.4.5版本,其中 dnn 模块支持较好.

- 下载链接
- 解压

```bash
unzip opencv- . . .zip
cd opencv- 3.4.5
```

- 安装cmake

```bash
sudo apt-get install cmake
```

- 依赖环境

```bash
sudo apt-get install build-essential libgtk . -dev libavcodec-dev libavformat-dev libjpeg-dev libswscale-
dev libtiff -dev
sudo apt-get install libgtk . -dev
sudo apt-get install pkg-config
```

- 建立build

```bash
mkdir build
cd build
```

- cmake

```bash
sudo cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..
```

- 编译

```bash
sudo make -j8
```

- 安装

```bash
sudo make install
```

- 配置环境

```bash
sudo gedit /etc/ld.so.conf
#添加 /usr/loacal/lib
sudo gedit /etc/bash.bashrc
#在文件末尾加入:
#PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig
#export PKG_CONFIG_PATH
source /etc/bash.bashrc
```

## Dlib配置

- 安装libboost

```bash
sudo apt-get install libboost-all-dev
```

- 下载dlib

```bash
git clone https://github.com/davisking/dlib.git
```

- build

```bash
cd dlib
mkdir build; cd build; cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVX_INSTRUCTIONS=1; cmake --build .
```

> -DDLIB_USE_CUDA=0 不使用cuda

> -DUSE_AVX_INSTRUCTIONS=1 使用cpu的AVX加速

- python扩展

```bash
cd ..
python setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA
```

## 编译程序

### FatigueDrivingDetection

```bash
cd FatigueDrivingDetection
mkdir build
cd build/
cmake .. -DCMAKE_BUILD_TYPE=Release | tee ../log/cmake_log
make -j |tee ../log/make_log
chmod +x FatigueDrivingDe
```

### lane_car_detect

```bash
cd lane_car_detect/
mkdir build
cd build
cmake ..
make
chmod +x lane_car_detect
./lane_car_detect
```

