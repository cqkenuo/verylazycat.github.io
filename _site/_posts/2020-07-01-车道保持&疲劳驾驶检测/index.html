<!DOCTYPE html>
<html>

<head>
  
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>车道保持&amp;疲劳驾驶检测 | lazycat</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="车道保持&amp;疲劳驾驶检测" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="[toc]" />
<meta property="og:description" content="[toc]" />
<link rel="canonical" href="http://localhost:4000/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/" />
<meta property="og:url" content="http://localhost:4000/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/" />
<meta property="og:site_name" content="lazycat" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-01T00:00:00-04:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/","headline":"车道保持&amp;疲劳驾驶检测","dateModified":"2020-07-01T00:00:00-04:00","datePublished":"2020-07-01T00:00:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/"},"description":"[toc]","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  
  
  <meta
  name="viewport"
  content="width=device-width, initial-scale=1.0, maximum-scale=1"
/>
<meta
  http-equiv="content-type"
  content="text/html; charset=utf-8"
/>
<link
  rel="alternate"
  href="/feed.xml"
  title="RSS"
  type="application/rss+xml"
/>

  
  <link
  rel="apple-touch-icon-precomposed"
  href="https://pic.cr173.com/up/2017-8/2017841818322084.jpg"
/>
<link
  rel="shortcut
  icon"
  href="https://pic.cr173.com/up/2017-8/2017841818322084.jpg"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/gh/poole/lanyon@v1.1.0/public/css/poole.min.css,gh/poole/lanyon@v1.1.0/public/css/lanyon.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"
/>

  
  <link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/Dreamer-Paul/Pio@2.4/static/pio.min.css"
/>
<script
  async="async"
  src="https://cdn.jsdelivr.net/combine/gh/Dreamer-Paul/Pio@2.4/static/l2d.min.js,gh/Dreamer-Paul/Pio@2.4/static/pio.min.js"
  onload='
      let pio_container = document.createElement("div");
      pio_container.classList.add("pio-container");
      pio_container.classList.add("right");
      pio_container.style.bottom = "-2rem";
      pio_container.style.zIndex = "1";
      document.body.insertAdjacentElement("beforeend", pio_container);
      let pio_action = document.createElement("div");
      pio_action.classList.add("pio-action");
      pio_container.insertAdjacentElement("beforeend", pio_action);
      let pio_canvas = document.createElement("canvas");
      pio_canvas.id = "pio";
      pio_canvas.style.width = "14rem";
      pio_canvas.width = "600";
      pio_canvas.height = "800";
      pio_container.insertAdjacentElement("beforeend", pio_canvas);
      let pio = new Paul_Pio({
        "mode": "fixed",
        "hidden": true,
        "night": "for(let i=7; i<16; ++i) if(document.body.classList.contains(`theme-base-0`+i.toString(16))) { document.body.classList.remove(`theme-base-0`+i.toString(16)); document.body.classList.add(`theme-base-0`+((i-6)%9+7).toString(16)); break; }",
        "content": {
          "link": ["https://jekyll-theme-WuK.wu-kan.cn"],
          "skin": ["要换成我的朋友吗？", "让她放个假吧~"],
          "hidden": true,
          "custom": [{
            "selector": "a",
            "type": "link",
          }, {
            "selector": ".sidebar-toggle",
            "text": "打开侧边栏叭~"
          }, {
            "selector": ".effect-info",
            "text": "哇，你发现了什么！"
          }, {
            "selector": "#sidebar-search-input",
            "text": "想搜索什么呢？很多干货哦！"
          }, {
            "selector": "#toc",
            "text": "这是目录~"
          }, {
            "selector": ".page-title",
            "text": "这是标题~"
          }, {
            "selector": ".v",
            "text": "评论没有审核，要对自己的发言负责哦~"
          }]
        },
        "model": [
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/33/model.2018.bls-winter.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/platelet-2/model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/xiaomai/xiaomai.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/mashiro/seifuku.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/imuncle/live2d/model/Violet/14.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/Kobayaxi/Kobayaxi.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/mikoto/mikoto.model.json",
          "https:\/\/cdn.jsdelivr.net/gh/xiaoski/live2d_models_collection/uiharu/uiharu.model.json"]
      });'
></script>

  
  <script
  src='https://zz.bdstatic.com/linksubmit/push.js'
  async="async"
></script>

  
  <script
  async="async"
  src="https://www.googletagmanager.com/gtag/js?id=UA-163543967-1"
  onload="
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-163543967-1');"
></script>

  
  <style>
  .wrap {
    transition-property: width,background-size,transform;
    transition-duration: .3s;
    transition-timing-function: ease-in-out;
    min-height: 100%;
    display: inline-block;
    background-size: 100% auto;
    background-position: 0% 0%;
    background-repeat: no-repeat;
    background-attachment: fixed;
    background-image: url(https://uploadstatic.mihoyo.com/contentweb/20200525/2020052518223387449.png);
  }
  @media (min-aspect-ratio: 2400/1850) {
    .wrap {
      background-image: url(https://uploadstatic.mihoyo.com/contentweb/20200525/2020052518223387449.png);
    }
  }
  .sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    width: calc(100% - 14rem);
    background-size: calc(100% - 14rem) auto;
    transform: translateX(14rem);
  }
  .layout-reverse.sidebar-overlay #sidebar-checkbox:checked ~ .wrap {
    transform: translateX(0);
  }
</style>

  
  <style>
  .sidebar,
  html,
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    font-family: PingFang SC, Menlo, Monaco, "Courier New", Microsoft JhengHei, monospace;
  }
</style>

  
  <style>
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    font-weight: bold;
  }
</style>

  
  <style>
  img {
    display: inline-block;
    margin: 0;
  }
</style>

  
  <style>
  ::-webkit-scrollbar {
    width: 3px;
    height: 3px;
  }
  ::-webkit-scrollbar-thumb {
    background-image: linear-gradient(45deg, Cyan 0%, Magenta 50%, Yellow 100%);
  }
</style>

  
  <style>
  ::selection {
    color: White;
    background: Black;
  }
</style>

  
</head>

<body
  class="theme-base-07 sidebar-overlay">
  
  
  
  <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
  <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"
     />
  <!-- Toggleable sidebar -->
  <div class="sidebar" id="sidebar">
    
    <div class="sidebar-item">
      <div class="effect effect-right_to_left">
        <img class="effect-img" src="https://pic.cr173.com/up/2017-8/2017841818322084.jpg" alt="img" />
        <div class="effect-info">
          lazycat<br/>
<a href="mailto:verylazycat@outlook.com">
  <i class="fas fa-envelope"></i>
</a>
<a href="https://github.com/verylazycat">
  <i class="fab fa-github"></i>
</a>

        </div>
      </div>
    </div>
    
    <nav class="sidebar-nav">
      
      <a class="sidebar-nav-item" href="/">
        <i class="fas fa-home fa-fw"></i> 首页
      </a>
      
      <a class="sidebar-nav-item" href="/comments/">
        <i class="fas fa-comments fa-fw"></i> 留言
      </a>
      
      <a class="sidebar-nav-item" href="/tags/">
        <i class="fas fa-tags fa-fw"></i> 标签
      </a>
      
      <a class="sidebar-nav-item" href="/archive/">
        <i class="fas fa-archive fa-fw"></i> 归档
      </a>
      
      <a class="sidebar-nav-item" href="/merger/">
        <i class="fas fa-coffee fa-fw"></i> 打赏
      </a>
      
    </nav>
    <div class="sidebar-item">
      
      <style>
  #sidebar-search-input {
    background: none;
    border: none;
    color: White;
    width: 100%;
  }
  #sidebar-search-results-container {
    overflow: auto auto;
    max-height: 50vh;
  }
</style>
<input
  id="sidebar-search-input"
  placeholder="搜索博文"
/>
<ol
  id="sidebar-search-results-container"
></ol>
<script
  src='https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.7/dest/simple-jekyll-search.min.js'
  async='async'
  onload='
    SimpleJekyllSearch({
      json: "/assets/simple-jekyll-search/search.json",
      searchInput: document.getElementById("sidebar-search-input"),
      resultsContainer: document.getElementById("sidebar-search-results-container"),
      searchResultTemplate: `<li><a href="{url}">{title}</a></li>`,
      limit: 999,
      fuzzy: true
    })'
></script>

      
      
      <style>
  #toc {
    overflow: auto auto;
    max-height: 50vh;
  }
</style>

      <ol id="toc">
  <li><a href="#%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97">功能模块</a></li>
  <li><a href="#%E8%BD%A6%E9%81%93%E7%BA%BF%E8%BD%A6%E5%86%B5%E8%AF%86%E5%88%AB%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B%E5%9B%BE">车道线&amp;车况识别总体流程图</a></li>
  <li><a href="#%E8%BD%A6%E9%81%93%E7%BA%BF%E8%AF%86%E5%88%AB%E4%B8%BB%E8%A6%81%E6%93%8D%E4%BD%9C">车道线识别主要操作</a></li>
  <li><a href="#-1"></a></li>
  <li><a href="#%E6%96%B9%E5%90%91%E5%88%A4%E6%96%AD%E9%80%BB%E8%BE%91">方向判断逻辑</a></li>
  <li><a href="#-2"></a></li>
  <li><a href="#%E8%BD%A6%E5%86%B5%E8%AF%86%E5%88%AB">车况识别</a>
    <ol>
      <li><a href="#%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8Cyolo">快速体验yolo</a></li>
    </ol>
  </li>
  <li><a href="#%E9%A9%BE%E9%A9%B6%E5%91%98%E8%A1%8C%E4%B8%BA%E5%8F%8A%E7%8A%B6%E6%80%81%E6%A3%80%E6%B5%8B">驾驶员行为及状态检测</a></li>
  <li><a href="#-3"></a></li>
  <li><a href="#%E7%8A%B6%E6%80%81%E7%89%B9%E5%BE%81%E5%88%A4%E6%96%AD%E4%BE%9D%E6%8D%AE">状态特征判断依据</a>
    <ol>
      <li><a href="#landmark%E7%AE%97%E6%B3%95">Landmark算法</a></li>
    </ol>
  </li>
  <li><a href="#ear%E5%8F%82%E8%80%83%E6%84%8F%E4%B9%89">EAR参考意义</a></li>
  <li><a href="#%E6%BA%90%E7%A0%81">源码</a>
    <ol>
      <li><a href="#lane_car_detect">lane_car_detect</a></li>
    </ol>
  </li>
  <li><a href="#%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8">安装使用</a>
    <ol>
      <li><a href="#opencv%E9%85%8D%E7%BD%AE">opencv配置</a></li>
      <li><a href="#dlib%E9%85%8D%E7%BD%AE">Dlib配置</a></li>
      <li><a href="#%E7%BC%96%E8%AF%91%E7%A8%8B%E5%BA%8F">编译程序</a>
        <ol>
          <li><a href="#fatiguedrivingdetection">FatigueDrivingDetection</a></li>
          <li><a href="#lane_car_detect-1">lane_car_detect</a></li>
        </ol>
      </li>
    </ol>
  </li>
</ol>
      
      
      <style>
  .sidebar-checkbox {
    display: none;
  }
  .sidebar-toggle {
    position: fixed;
  }
</style>

      
      <style>
  .effect {
    margin: 1rem;
    perspective: 900px;
  }
  .effect-info {
    text-align: center;
    backface-visibility: hidden;
    position: absolute;
    top: 0;
    transform-style: preserve-3d;
  }
  .effect-img {
    z-index: 11;
    width: 100%;
    height: 100%;
    position: relative;
    transition: all 0.5s ease-in-out;
  }
  .effect-img:before {
    position: absolute;
    display: block;
  }
  .effect-right_to_left .effect-img {
    transform-origin: 0% 50%;
  }
  .effect-right_to_left:hover .effect-img {
    transform: rotate3d(0, 1, 0, -180deg);
  }
</style>

      
      <div>
  <i class="fas fa-cog fa-spin fa-fw"></i>
  <span id="run_time_day">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>天
  <span id="run_time_hour">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>时
  <span id="run_time_minute">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>分
  <span id="run_time_second">
    <i class="fas fa-spinner fa-pulse"></i>
  </span>秒
  <script>
    setInterval(function (d,h,m,s,b) {
      function setzero(i) {
        return i < 10 ? "0" + i : i;
      }
      let BirthDay = new Date(b);
      let today = new Date();
      let timeold = (today.getTime() - BirthDay.getTime());
      let sectimeold = timeold / 1000;
      let secondsold = Math.floor(sectimeold);
      let msPerDay = 24 * 60 * 60 * 1000;
      let e_daysold = timeold / msPerDay;
      let daysold = Math.floor(e_daysold);
      let e_hrsold = (e_daysold - daysold) * 24;
      let hrsold = Math.floor(e_hrsold);
      let e_minsold = (e_hrsold - hrsold) * 60;
      let minsold = Math.floor((e_hrsold - hrsold) * 60);
      let seconds = Math.floor((e_minsold - minsold) * 60);
      d.textContent = daysold;
      h.textContent = setzero(hrsold);
      m.textContent = setzero(minsold);
      s.textContent = setzero(seconds);
    },
    1000,
    document.getElementById("run_time_day"),
    document.getElementById("run_time_hour"),
    document.getElementById("run_time_minute"),
    document.getElementById("run_time_second"),
    "05/02/2020 11:03:56")// 这是我第一篇博客的时间
  </script>
</div>

      
      <div>
  <div>
    <i class="fas fa-eye fa-fw"></i>
    <span id="busuanzi_value_page_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>次
  </div>
  <div>
    <i class="fas fa-paw fa-fw"></i>
    <span id="busuanzi_value_site_pv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>枚
  </div>
  <div>
    <i class="fas fa-user-friends fa-fw"></i>
    <span id="busuanzi_value_site_uv">
      <i class="fas fa-spinner fa-pulse"></i>
    </span>人
  </div>
  <script
    src='https://cdn.jsdelivr.net/npm/busuanzi@2.3.0'
    async='async'
  ></script>
</div>

      
      <div>
  <i class="fas fa-copyright fa-fw"></i>
  2020-2022 lazycat
</div>

      
      <div>
  <i class="fas fa-info-circle fa-fw"></i>
  <a href="http://beian.miit.gov.cn">
    蜀ICP备20011774号
  </a>
</div>

      
      
    </div>
  </div>
  <!-- Wrap is the content to shift when toggling the sidebar. We wrap the content to avoid any CSS collisions with our real content. -->
  
  <div class="wrap">
    
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/katex@0.11.1/dist/katex.min.js,npm/katex@0.11.1/dist/contrib/mathtex-script-type.min.js,npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  defer="defer"
  onload='renderMathInElement(document.body, { delimiters: [{ left: "$", right: "$", display: false }] })'
></script>



<style>
  pre.language-mermaid,
  code.language-mermaid {
    display: none;
  }
</style>
<script
  src="https://cdn.jsdelivr.net/npm/mermaid@8.5.1/dist/mermaid.min.js"
  defer="defer"
  onload='
    for(let x of document.getElementsByClassName("language-mermaid"))
      if(x.nodeName=="CODE")
      {
        let m = document.createElement("div");
        m.classList.add("mermaid");
        m.textContent = x.textContent;
        x.parentNode.insertAdjacentElement("beforebegin", m);
      }'
></script>



<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/combine/npm/prismjs@1.20.0/plugins/line-numbers/prism-line-numbers.min.css,npm/prismjs@1.20.0/plugins/toolbar/prism-toolbar.min.css,gh/PrismJS/prism-themes@1955cfef6953b3a59e66016e8a1e016b45d6cc79/themes/prism-nord.min.css"
/>
<script
  src="https://cdn.jsdelivr.net/combine/npm/prismjs@1.20.0/components/prism-core.min.js,npm/prismjs@1.20.0/plugins/autoloader/prism-autoloader.min.js,npm/prismjs@1.20.0/plugins/line-numbers/prism-line-numbers.min.js,npm/prismjs@1.20.0/plugins/toolbar/prism-toolbar.min.js"
  defer="defer"
  onload='
    Prism.plugins.autoloader.languages_path = "https:\/\/cdn.jsdelivr.net/npm/prismjs/components/";
    for(let x of document.getElementsByTagName("pre"))
      x.classList.add("line-numbers");
    Prism.plugins.toolbar.registerButton("select-code", function (env) {
      let button = document.createElement("button");
      button.textContent = "select this " + env.language;
      button.addEventListener("click", function () {
        if (document.body.createTextRange) {
          let range = document.body.createTextRange();
          range.moveToElementText(env.element);
          range.select();
        } else if (window.getSelection) {
          let selection = window.getSelection();
          let range = document.createRange();
          range.selectNodeContents(env.element);
          selection.removeAllRanges();
            selection.addRange(range);
        }
      });
      return button;
    })'
></script>



<style>
  pre {
    max-height: 50vh;
    overflow: auto;
  }
</style>


<style>
  @media (min-width: 56em) {
    .container {
      max-width: 66.6%;
    }
  }
</style>


<style>
  .masthead,
  .container.content {
    padding-top: 1rem;
    padding-bottom: 1rem;
    box-shadow: 0 0 .75rem rgba(0, 0, 0, 0.1);
    background-color: rgba(255, 255, 255, 0.95);
    animation-duration: 2s;
    animation-name: fadeIn;
  }
  @keyframes fadeIn {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }
</style>



<div class="masthead">
  <h3 class="container masthead-title">
    
    车道保持&疲劳驾驶检测
    <a href="/" title="Home">
      <small>
        lazycat
      </small>
    </a>
    
  </h3>
</div>

<div class="container content">
  <div class="post">
  <span class="post-date">
    
    <i class="fas fa-calendar-day fa-fw"></i>
    01 Jul 2020
    
    
    <i class="fas fa-file-word fa-fw"></i>
    24837字
    
    
    <i class="fas fa-clock fa-fw"></i>
    83分
    
    
    <span class="leancloud-visitors" id="/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/" data-xid="/_posts/2020-07-01-%E8%BD%A6%E9%81%93%E4%BF%9D%E6%8C%81&%E7%96%B2%E5%8A%B3%E9%A9%BE%E9%A9%B6%E6%A3%80%E6%B5%8B/" data-flag-title="车道保持&疲劳驾驶检测">
      <i class="fas fa-book-reader fa-fw"></i>
      <span class="leancloud-visitors-count">
        <i class="fas fa-spinner fa-pulse"></i>
      </span>次
    </span>
    
    
    
    <i class="fas fa-tag fa-fw"></i>
    机器学习
    
    
    <br/>
<i class="fas fa-coffee fa-fw"></i>
<a href="/merger/">如果这篇博客帮助到你，可以请我喝一杯咖啡~</a>
<br/>
<i class="fab fa-creative-commons-by fa-fw"></i>
<a
  href="https://creativecommons.org/licenses/by/4.0/deed.zh"
  rel="license">
  CC BY 4.0
</a>
（除特别声明或转载文章外）

    
  </span>
  <p>[toc]</p>

<p><a href="https://github.com/verylazycat/DriverAssistanceSystem">github</a></p>

<blockquote>
  <p>有问题可私信我</p>
</blockquote>

<h1 id="功能模块">功能模块</h1>

<ul>
  <li>车道保持
    <ul>
      <li>车道线识别</li>
      <li>航向判断</li>
    </ul>
  </li>
  <li>驾驶员行为及状态检测
    <ul>
      <li>疲劳检测</li>
    </ul>
  </li>
</ul>

<h1 id="车道线车况识别总体流程图">车道线&amp;车况识别总体流程图</h1>

<h1><img src="/img/detect.png" alt="detect" /></h1>

<p>对输入的每一帧图像主要有如下处理：</p>

<p>1.车道线识别：
	1.1.降噪
	1.2.边缘检测
	1.3.ROI处理
	1.4.霍夫线获取
	1.5.路线获取
	1.6.渲染</p>

<p>2.车况识别：
	2.1.加载yolo网络
	2.2.前向传播
	3.3.渲染</p>

<h1 id="车道线识别主要操作">车道线识别主要操作</h1>

<h1 id="-1"><img src="/img/车道线处理.png" alt="车道线处理" /></h1>

<h1 id="方向判断逻辑">方向判断逻辑</h1>

<h1 id="-2"><img src="/img/方向判断.png" alt="方向判断" /></h1>

<p>获得道路线后，即我们获取了两个方程:
<script type="math/tex">y1 = a1x1 + b1\\
y2 = a2x2 + b2</script>
计算两直线交点(x0,y0),即左图所提的消失点；
此外，我们已知图像水平方向中心直线：x；</p>

<p>由此，我们有如下判断依据：</p>

<ul>
  <li>x0 &gt; x + thr_vp :右转</li>
  <li>x0 &lt; x - thr_vp:左转</li>
  <li>x0 &gt;= (x - thr_vp) &amp;&amp; x0 &lt;= (x + thr_vp)：直线</li>
</ul>

<blockquote>
  <p>注：thr_vp为调整参数，根据实际情况调试</p>
</blockquote>

<h1 id="车况识别">车况识别</h1>

<p>基于深度学习的目标检测与识别算法大致分为以下三大类:
1.基于区域建议的目标检测与识别算法，如R-CNN, Fast-R-CNN, Faster-R-CNN;
2.基于回归的目标检测与识别算法，如YOLO, SSD;
3.基于搜索的目标检测与识别算法，如基于视觉注意的AttentionNet；</p>

<hr />

<p>此处识别采用YOLO算法,其优点如下：
1.速度非常快。在Titan X GPU上的速度是45 fps，加速版的YOLO差不多是150fps；
2.YOLO是基于图像的全局信息进行预测的；
3.泛化能力强；
4.准确率高；</p>

<ul>
  <li>具体算法参考yolo论文</li>
  <li>训练参考<a href="https://pjreddie.com/darknet/yolo/">DarkNet</a></li>
</ul>

<blockquote>
  <p>注：由于笔记本计算能力有限，此处采用开源coco数据集训练的yolo模型，支持80个分类识别，具体分类参考配置文件</p>
</blockquote>

<h2 id="快速体验yolo">快速体验yolo</h2>

<ul>
  <li>安装</li>
</ul>

<pre><code class="language-bash">git clone https://github.com/pjreddie/darknet.git
cd darknet
make
</code></pre>

<p>输出如下内容即安装成功</p>

<pre><code class="language-bash">mkdir -p obj
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast....
.....
gcc -I/usr/local/cuda/include/ -Wall -Wfatal-errors -Ofast -lm....
</code></pre>

<blockquote>
  <p>注意:根据自己环境调整 Makefile ,尤其是 GPU , CUDNN , OPENCV</p>
</blockquote>

<ul>
  <li>下载weights文件</li>
</ul>

<pre><code class="language-bash">wget https://pjreddie.com/media/files/yolov .weights
</code></pre>

<ul>
  <li>测试</li>
</ul>

<pre><code class="language-bash">./darknet detect cfg/yolov .cfg yolov .weights data/dog.jpg
</code></pre>

<h1 id="驾驶员行为及状态检测">驾驶员行为及状态检测</h1>

<h1 id="-3"><img src="/img/驾驶员行为及状态检测.png" alt="驾驶员行为及状态检测" /></h1>

<p>关键操作有如下：</p>

<p>1.保存驾驶人员启动程序时的状态数据</p>

<p>2.判断是否无人驾驶</p>

<p>3.依据记录的状态数据判断当前技术人员状态是否异常</p>

<h1 id="状态特征判断依据">状态特征判断依据</h1>

<p>有如下内容需要了解:</p>

<p>1.“眼睛纵横比”（EAR）
我们可以应用面部标志检测来定位脸部的重要区域，包括眼睛，眉毛，鼻子，耳朵和嘴巴</p>

<p>2.EAR计算公式
<script type="math/tex">EAR = (||p_{2} - p_{6}||+||p_{3}-p_{5}||)/(2||p_{1} -p_{4}||)</script>
<img src="/img/eyeEar.png" alt="eyeEar" /></p>

<blockquote>
  <p>详细内容参考Soukupová和Čech在其2016年的论文Real-Time Eye Blink Detection using Facial Landmarks</p>
</blockquote>

<h2 id="landmark算法">Landmark算法</h2>

<p>点标记》一文中有效果和标定点序号的示意图。今后可采用landmark中的点提取眼睛区域、嘴巴区
域用于疲劳检测,提取鼻子等部分可用于3D姿态估计。
Dlib库使用《One Millisecond Face Alignment with an Ensemble of Regression Trees》CVPR2014
中提及的算法:ERT(ensemble of regression trees)级联回归,即基于梯度提高学习的回归树方法。
该算法使用级联回归因子,首先需要使用一系列标定好的人脸图片作为训练集,然后会生成一个模型。
使用基于特征选择的相关性方法把目标输出投影到一个随机方向w上,并且选择一对特征(u,v),使
得Ii(u )-Ii(v )与被投影的目标wTri在训练数据上拥有最高的样本相关性。
当获得一张图片后,算法会生成一个initial shape就是首先估计一个大致的特征点位置,然后采用
gradient boosting算法减小initial shape 和 ground truth 的平方误差总和。用最小二乘法来最小化误
差,得到每一级的级联回归因子。核心公式如下:
<script type="math/tex">\hat{S}^{t+1} = \hat{S}+r_{t}(I,\hat{t}^{t})</script>
示当前级的回归器regressor。回归器的输入参数为图像I和上一级回归器更新后的shape,采用的特征可
以是灰度值或者其它。每个回归器由很多棵树(tree)组成,每棵树参数是根据current shape和ground
truth的坐标差和随机挑选的像素对训练得到的。</p>

<p>与LBF不同,ERT是在学习Tree的过程中,直接将shape的更新值ΔS存入叶子结点leaf node.初始位
置S在通过所有学习到的Tree后,meanshape加上所有经过的叶子结点的ΔS,即可得到最终的人脸关
键点位置。</p>

<h1 id="ear参考意义">EAR参考意义</h1>

<p>“眼睛纵横比”(EAR):我们可以应用面部标志检测来定位脸部的重要区域,包括眼睛,眉毛,鼻子,
耳朵和嘴巴.</p>

<p>1.其中p1…p6是2D面部地标位置;
2.方程的分子是计算垂直眼睛标志之间的距离，而分母是计算水平眼睛标志之间的距离，因为只有一组水平点，但是有两组垂直点，所以进行加权分母</p>

<p><img src="/img/EAR.png" alt="EAR" /></p>

<blockquote>
  <p>当人眼闭眼时，EAR急剧减小，我们利用这一点去检测人眼闭眼状态</p>
</blockquote>

<p><img src="/img/EARTEST.png" alt="EARTEST" /></p>

<h1 id="源码">源码</h1>

<ul>
  <li>FatigueDrivingDetection</li>
</ul>

<blockquote>
  <p>main</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-05 14:56:20 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:39:19
 */
#include &lt;main.h&gt;
#include &lt;render_face.h&gt;
#include &lt;Compute.h&gt;
#include &lt;BuzzerControl.h&gt;
#include &lt;fatigueDetection.h&gt;
#include &lt;getTime.h&gt;
int main()
{
	//判断的基础信息
	double LeftEyeBase,RightEyeBase,InnerLipBase;
	//标志位,用于第一次录入基础信息
	int Base = 1;
	//记录哈欠次数
	int innerLipCounts = 0;
	//记录眯眼次数
	int squintingCounts = 0;
	try
	{
		//读取摄像头
		cv::VideoCapture cap(0);
		// 窗体大小设置,看需求
		//cap.set(CV_CAP_PROP_FRAME_WIDTH, 640);  
		//cap.set(CV_CAP_PROP_FRAME_HEIGHT, 480);  
		//模型加载 
		frontal_face_detector detector = get_frontal_face_detector();
		shape_predictor pose_model;
		deserialize(datPath) &gt;&gt; pose_model;
 
		int count = 0;
		std::vector&lt;dlib::rectangle&gt; faces;

		while (1)
		{
			cv::Mat img, img_small;
			cap &gt;&gt; img;
			//文字
			cv::putText(img,"s:save,q:quit",cv::Point(img.rows/2,img.cols/2),FONT_HERSHEY_SIMPLEX,2,Scalar(0,0,255),1,8,false);
			cv::resize(img, img_small, cv::Size(), 1.0 / RATIO, 1.0 / RATIO);
 
			cv_image&lt;bgr_pixel&gt; cimg(img);
			cv_image&lt;bgr_pixel&gt; cimg_small(img_small);
 
			//人脸检测   
			if (count++ % SKIP_FRAMES == 0) {
				faces = detector(cimg_small);
			}
			cout &lt;&lt; "检测人数:" &lt;&lt; faces.size() &lt;&lt; endl;
			//无人状态
			if(faces.empty())
			{
				cout  &lt;&lt; "\033[31m警告:无人状态\033[0m"&lt;&lt; endl;
				//蜂鸣器功能,后续添加
				// BuzzerControl();
				getCurrentTime();
			}

			// 关键点检测  
			std::vector&lt;full_object_detection&gt; shapes;
			for (unsigned long i = 0; i &lt; faces.size(); ++i) 
			{
				dlib::rectangle r(
					(long)(faces[i].left() * RATIO),
					(long)(faces[i].top() * RATIO),
					(long)(faces[i].right() * RATIO),
					(long)(faces[i].bottom() * RATIO)
				);
				// 关键点保存
				full_object_detection shape = pose_model(cimg, r);
				shapes.push_back(shape);
 
				//渲染画线
				render_face(img, shape);
				double rightEye = RightEyeCompute(img,shape);
				double leftEye = LeftEyeCompute(img,shape);
				double innerLip = InnerLipCompute(img,shape);
				cout&lt;&lt;"-------------"&lt;&lt;endl;

				//第一次识别信息导入,以此为后续判断的标注
				//RightEyeBase,LeftEyeBase,innerLipBase
				if(Base)
				{
					RightEyeBase = rightEye;
					LeftEyeBase = leftEye;
					InnerLipBase = innerLip;
					//退出信息录入,避免后续覆盖
					Base--;
					cout&lt;&lt;"用户数据录入成功&gt;&gt;&gt;初始化成功!"&lt;&lt;endl;
				}
				int temp = fatigueDetection(LeftEyeBase,leftEye,RightEyeBase,rightEye,InnerLipBase,innerLip,innerLipCounts,squintingCounts);
				innerLipCounts += temp;
				squintingCounts += temp;
				//疲劳驾驶
				// innerLipCounts 哈欠次数 需要实际调试确定临界点
				if(innerLipCounts &gt;= 50)
				{
					//红色打印
					cout  &lt;&lt; "\033[31m警告:疲劳驾驶\033[0m"&lt;&lt; endl;	
					getCurrentTime();	
				}
				// squintingCounts 眯眼次数
				if(squintingCounts &gt;= 50)
				{
					//红色打印
					cout  &lt;&lt; "\033[31m警告:疲劳驾驶\033[0m"&lt;&lt; endl;	
					getCurrentTime();
				}
				//----------------------------------------------------
			}
			// std::cout &lt;&lt; "count:" &lt;&lt; count &lt;&lt; std::endl;
			if (img.empty())
			{
				cerr&lt;&lt;"img is mepty!"&lt;&lt;endl;
				getCurrentTime();
				break;
			}
			imshow("Frame", img);
			// Q q退出
			char c = (char)waitKey(25);
			if (c == 'Q' || c == 'q')
			{
				cout&lt;&lt;"退出成功"&lt;&lt;endl;
				getCurrentTime();
				break;
			}
			if(c == 's'||c == 'S')
			{
				cv::imwrite("../img/img.png",img);
				cout&lt;&lt;"保存成功"&lt;&lt;endl;
				getCurrentTime();
			}
		}
	}
	catch (serialization_error&amp; e)
	{
		cout &lt;&lt; "模型下载链接 " &lt;&lt; endl;
		cout &lt;&lt; "http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" &lt;&lt; endl;
		cout &lt;&lt; endl &lt;&lt; e.what() &lt;&lt; endl;
		getCurrentTime();
	}
	catch (exception&amp; e)
	{
		cout &lt;&lt; e.what() &lt;&lt; endl;
		getCurrentTime();
	}
	return 0;
}
</code></pre>

<blockquote>
  <p>BuzzerControl.h</p>
</blockquote>

<pre><code class="language-c">/*
 * @Author: verylazycat 
 * @Date: 2020-02-07 12:15:16 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:18:52
 */
// 蜂鸣器控制
#include &lt;main.h&gt;
int BuzzerControl()
{
    return 0;
}
</code></pre>

<blockquote>
  <p>Compute.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 12:29:42 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:19:28
 */
#include &lt;main.h&gt;
#include &lt;cmath&gt;
// 欧式距离计算
double PointsCompute(int x1,int y1,int x2,int y2)
{
    double results = 0;
    results = sqrt(pow(x1-x2,2) + pow(y1 - y2,2));
    return results;
}
// Right Eye:42~47
double RightEyeCompute(cv::Mat &amp;img,const dlib::full_object_detection&amp; d)
{
    double result = 0;
    std::vector&lt;cv::Point&gt; points;
    for(int i = 42;i &lt;=47;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[5].x,points[5].y) + PointsCompute(points[2].x,points[2].y,points[4].x,points[4].y))/(2*PointsCompute(points[0].x,points[0].y,points[3].x,points[3].y)); 
    cout&lt;&lt;"右眼高宽比例:";
    cout&lt;&lt;result&lt;&lt;endl;
    return result;
}
//Left Eye:36 ~ 41
double LeftEyeCompute(cv::Mat &amp;img,const dlib::full_object_detection&amp; d)
{
    double result = 0;
    std::vector&lt;cv::Point&gt; points;
    for(int i = 36;i &lt;=41;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[5].x,points[5].y) + PointsCompute(points[2].x,points[2].y,points[4].x,points[4].y))/(2*PointsCompute(points[0].x,points[0].y,points[3].x,points[3].y)); 
    cout&lt;&lt;"左眼高宽比例:";
    cout&lt;&lt;result&lt;&lt;endl;
    return result;
}
//inner lip :60 ~ 67
double InnerLipCompute(cv::Mat &amp;img,const dlib::full_object_detection&amp; d)
{
    double result = 0;
    std::vector&lt;cv::Point&gt; points;
    for(int i = 60;i &lt;=67;++i)
    {
        points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
    }
    result = (PointsCompute(points[1].x,points[1].y,points[7].x,points[7].y) + PointsCompute(points[3].x,points[3].y,points[5].x,points[5].y))/(2*PointsCompute(points[0].x,points[0].y,points[4].x,points[4].y)); 
    cout&lt;&lt;"内嘴唇高宽比例:";
    cout&lt;&lt;result&lt;&lt;endl;
    return result;
}
</code></pre>

<blockquote>
  <p>fatigueDetection.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-09 12:41:21 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:41:51
 */
//警告状态
#include &lt;main.h&gt;
int fatigueDetection(double leftEyeBase,double leftEye,double rightEyeBase,double rightEye,double innerLipBase,double innerLip,int innerLipCounts,int squintingCounts)
{
    //当内嘴唇高宽比例大于基础高宽比0.,定义位打哈欠
    if(innerLip - innerLipBase &gt;= 0.3)
    {
        //绿色打印
        cout  &lt;&lt; "\033[32m警告:哈欠:\033[0m"&lt;&lt;innerLipCounts&lt;&lt; endl;
        //计数
        return 1;
    }
    if(leftEyeBase - leftEye &gt;=0.1 || rightEyeBase - rightEye &gt;= 0.1)
    {
        //绿色打印
        cout  &lt;&lt; "\033[32m警告:眯眼:\033[0m"&lt;&lt;squintingCounts&lt;&lt; endl;
        //计数
        return 1;
    }
    if((leftEye + rightEye)/2 &lt; 0.2)
    {
        // 绿色打印
        cout  &lt;&lt; "\033[32m警告:闭眼\033[0m"&lt;&lt; endl;	
    }
    return 0;
}
</code></pre>

<blockquote>
  <p>getTime.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-09 13:27:35 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:37:06
 */
#include &lt;main.h&gt;
void getCurrentTime()
{
    time_t rawtime;
    struct tm *ptminfo;
 
    time(&amp;rawtime);
    ptminfo = localtime(&amp;rawtime);
    printf("current: %02d-%02d-%02d %02d:%02d:%02d\n",
            ptminfo-&gt;tm_year + 1900, ptminfo-&gt;tm_mon + 1, ptminfo-&gt;tm_mday,
            ptminfo-&gt;tm_hour, ptminfo-&gt;tm_min, ptminfo-&gt;tm_sec);
}
</code></pre>

<blockquote>
  <p>main.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 11:26:56 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-09 13:36:59
 */
#ifndef __BUILD__
#define __BUILD__
#include &lt;dlib/opencv.h&gt;  
#include &lt;opencv2/opencv.hpp&gt;  
#include &lt;dlib/image_processing/frontal_face_detector.h&gt;  
#include &lt;dlib/image_processing/render_face_detections.h&gt;  
#include &lt;dlib/image_processing.h&gt;  
#include &lt;dlib/gui_widgets.h&gt;  
#include "opencv2/opencv.hpp"
#include &lt;iostream&gt;
#include &lt;ctime&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/ioctl.h&gt;

using namespace dlib;
using namespace std;
using namespace cv;

#define RATIO 4  
#define SKIP_FRAMES 2 

cv::String datPath = "../config/shape_predictor_68_face_landmarks.dat";

#endif
</code></pre>

<blockquote>
  <p>render_face.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-02-06 11:57:30 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-02-08 13:19:01
 */
#include &lt;main.h&gt;
// 画线 
void draw_polyline(cv::Mat &amp;img, const dlib::full_object_detection&amp; d, const int start, const int end, bool isClosed = false)
{
	std::vector &lt;cv::Point&gt; points;
	for (int i = start; i &lt;= end; ++i)
	{
		points.push_back(cv::Point(d.part(i).x(), d.part(i).y()));
	}
	cv::polylines(img, points, isClosed, cv::Scalar(255, 0, 0), 2, 16);
}
// 渲染 
void render_face(cv::Mat &amp;img, const dlib::full_object_detection&amp; d)
{
	DLIB_CASSERT
	(
		d.num_parts() == 68,
		"\n\t Invalid inputs were given to this function. "
		&lt;&lt; "\n\t d.num_parts():  " &lt;&lt; d.num_parts()
	);
 
	draw_polyline(img, d, 0, 16);           // Jaw line
	draw_polyline(img, d, 17, 21);          // Left eyebrow
	draw_polyline(img, d, 22, 26);          // Right eyebrow
	draw_polyline(img, d, 27, 30);          // Nose bridge
	draw_polyline(img, d, 30, 35, true);    // Lower nose
	draw_polyline(img, d, 36, 41, true);    // Left eye
	draw_polyline(img, d, 42, 47, true);    // Right Eye
	draw_polyline(img, d, 48, 59, true);    // Outer lip
	draw_polyline(img, d, 60, 67, true);    // Inner lip
 
}
</code></pre>

<blockquote>
  <p>CMakeLists.txt</p>
</blockquote>

<pre><code class="language-makefile">#SET CMAKE VERSION
CMAKE_MINIMUM_REQUIRED(VERSION 2.8)
# 优化
# SET(CMAKE_C_FLAGS "${CMAKE_C_FLAGS} -O2")
SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Ofast")
#SET PROJECT NAME
SET(PROJECT_NAME FatigueDrivingDetection)
#BUILD PROJECT NAME
PROJECT(${PROJECT_NAME})
#FIND OPENCV 
FIND_PACKAGE(OpenCV REQUIRED)
INCLUDE_DIRECTORIES(${OpenCV_INCLUDE_DIRS})
#FIND DLIB
FIND_PACKAGE(dlib REQUIRED)
INCLUDE_DIRECTORIES(${dlib_INCLUDE_DIRS})
#PRINT STATUS
MESSAGE(STATUS "Project: ${PROJECT_NAME}")
MESSAGE(STATUS "------------------------------------------------------")
MESSAGE(STATUS "OpenCV library status:")
MESSAGE(STATUS "version: ${OpenCV_VERSION}")
MESSAGE(STATUS "libraries: ${OpenCV_LIBS}")
MESSAGE(STATUS "include path: ${OpenCV_INCLUDE_DIRS}")
MESSAGE(STATUS "------------------------------------------------------")
MESSAGE(STATUS "DLIB library status:")
MESSAGE(STATUS "version: ${dlib_VERSION}")
MESSAGE(STATUS "libraries: ${dlib_LIBS}")
MESSAGE(STATUS "include path: ${dlib_INCLUDE_DIRS}")
MESSAGE(STATUS "------------------------------------------------------")
#GET CODE FROM SRC FOLDER
AUX_SOURCE_DIRECTORY(src DIR_SRCS)
include_directories(include)
MESSAGE(STATUS "Src file: ${DIR_SRCS}")
#编译可执行程序
ADD_EXECUTABLE(${PROJECT_NAME} ${DIR_SRCS})
#添加链接库
TARGET_LINK_LIBRARIES(${PROJECT_NAME} ${OpenCV_LIBS} ${dlib_LIBRARIES})
</code></pre>

<h2 id="lane_car_detect">lane_car_detect</h2>

<blockquote>
  <p>main.cpp</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 12:39:24 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-18 13:12:06
 */
#include "yolo_car_detect.h"
#include "lane_detect.h"
#include &lt;iostream&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;error.h&gt;

// 摄像头调用
// #define __USE__CAP_0__

//视频测试
#define __USE__VIDEO__

int main(int argc ,char *argv[]) 
{
	
	#ifdef  __USE__CAP_0__
	//摄像头测试
	cv::VideoCapture cap(0);
	#endif

	#ifdef  __USE__VIDEO__
	cv::VideoCapture cap("../video/test.mp4");
	#endif
	
	if (!cap.isOpened())
		return -1;
	//config检测
	configFileDect;
	//导入网络
    Net net = readNetFromDarknet(modelConfiguration, modelWeights);
    net.setPreferableBackend(DNN_BACKEND_OPENCV);
    net.setPreferableTarget(DNN_TARGET_CPU);
    Mat frame, blob;
	//lane检测
	LaneDetector lanedetector; 
	// frame处理
	while (i &lt; 540) {
		//frame为空
		if (!cap.read(frame))
			break;
		//按照预先设定的参数初始化frame
        blobFromImage(frame, blob, 1/255.0, cvSize(inpWidth, inpHeight), Scalar(0,0,0), true, false);
        //将预处理后的frame输入网络
        net.setInput(blob);
        // 前向传播获取outs
        vector&lt;Mat&gt; outs;
        net.forward(outs, getOutputsNames(net));
        // 值信度抑制
		postprocess(frame, outs);
		//time
        vector&lt;double&gt; layersTimes;
        double f = getTickFrequency() / 1000;
        double t = net.getPerfProfile(layersTimes) / f;
        string label = format("Inference time for a frame : %.2f ms", t);
        putText(frame, label, Point(0, 15), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(0, 0, 255));
		// 降噪
		img_denoise = lanedetector.deNoise(frame);
		//边缘检测
		img_edges = lanedetector.edgeDetector(img_denoise);
		// ROI
		img_mask = lanedetector.mask(img_edges);
		//霍夫线获取
		lines = lanedetector.houghLines(img_mask);
		if (!lines.empty())
		{
			//区分左右
			left_right_lines = lanedetector.lineSeparation(lines, img_edges);
			//过滤
			lane = lanedetector.regression(left_right_lines, frame);
			//消失点预测方向
			turn = lanedetector.predictTurn();
			//航向输出
			cout&lt;&lt;turn&lt;&lt;endl;
			//渲染
			flag_plot = lanedetector.plotLane(frame, lane, turn);
			cv::waitKey(25);
		}
		else {
			flag_plot = -1;
		}
	}
	return flag_plot;
}
</code></pre>

<blockquote>
  <p>lane_detect.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 18:45:15 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-17 18:46:14
 */
#include &lt;string&gt;
#include &lt;opencv2/opencv.hpp&gt;
class LaneDetector 
{
private:
	double img_size;
	double img_center;
    // 左边界
	bool left_flag = false;  
    // 右边界
	bool right_flag = false;
    // 车道线方程  
    // y = m*x + b
	cv::Point right_b;  
	double right_m;  
	cv::Point left_b; 
	double left_m;  

public:
    //高斯模糊
	cv::Mat deNoise(cv::Mat inputImage);  
    // 边缘提取
	cv::Mat edgeDetector(cv::Mat img_noise);
    // ROI  
	cv::Mat mask(cv::Mat img_edges);  
    // 霍夫线检测
	std::vector&lt;cv::Vec4i&gt; houghLines(cv::Mat img_mask);  
    //路线提取
	std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; lineSeparation(std::vector&lt;cv::Vec4i&gt; lines, cv::Mat img_edges);  
    //车道线获取,一条
	std::vector&lt;cv::Point&gt; regression(std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; left_right_lines, cv::Mat inputImage);  
    // 转向决策，消失点决策
	std::string predictTurn();  
    // 渲染绘画
	int plotLane(cv::Mat inputImage, std::vector&lt;cv::Point&gt; lane, std::string turn);  
};

cv::Mat LaneDetector::deNoise(cv::Mat inputImage) {
	cv::Mat output;
	cv::GaussianBlur(inputImage, output, cv::Size(3, 3), 0, 0);
	return output;
}

cv::Mat LaneDetector::edgeDetector(cv::Mat img_noise) {
	cv::Mat output;
	cv::Mat kernel;
	cv::Point anchor;

	//灰度化
	cv::cvtColor(img_noise, output, cv::COLOR_RGB2GRAY);
	// 二值化
	cv::threshold(output, output, 140, 255, cv::THRESH_BINARY);

    // 偏离警告
	anchor = cv::Point(-1, -1);
	kernel = cv::Mat(1, 3, CV_32F);
	kernel.at&lt;float&gt;(0, 0) = -1;
	kernel.at&lt;float&gt;(0, 1) = 0;
	kernel.at&lt;float&gt;(0, 2) = 1;

	//边缘提取
	cv::filter2D(output, output, -1, kernel, anchor, 0, cv::BORDER_DEFAULT);
	// cv::imshow("output", output);
	return output;
}

cv::Mat LaneDetector::mask(cv::Mat img_edges) {
	cv::Mat output;
    // 创建mask
	cv::Mat mask = cv::Mat::zeros(img_edges.size(), img_edges.type());
	// 定位点
    cv::Point pts[4] = {
		cv::Point(210, 720),
		cv::Point(550, 450),
		cv::Point(717, 450),
		cv::Point(1280, 720)
	};
    // 区域填充
	cv::fillConvexPoly(mask, pts, 4, cv::Scalar(255, 0, 0));
	//图像和mask相乘输出
	cv::bitwise_and(img_edges, mask, output);
	return output;
}

//霍夫直线检测
std::vector&lt;cv::Vec4i&gt; LaneDetector::houghLines(cv::Mat img_mask) {
	std::vector&lt;cv::Vec4i&gt; line;
	HoughLinesP(img_mask, line, 1, CV_PI / 180, 20, 20, 30);

	return line;
}
//路线提取
//过滤line
//左右两条line
std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; LaneDetector::lineSeparation(std::vector&lt;cv::Vec4i&gt; lines, cv::Mat img_edges) {
	std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; output(2);
	size_t j = 0;
	cv::Point ini;
	cv::Point fini;
    //斜率限制阈值
	double slope_thresh = 0.3;
	std::vector&lt;double&gt; slopes;
	std::vector&lt;cv::Vec4i&gt; selected_lines;
	std::vector&lt;cv::Vec4i&gt; right_lines, left_lines;

	// 斜率计算
	for (auto i : lines) {
		ini = cv::Point(i[0], i[1]);
		fini = cv::Point(i[2], i[3]);

		// m = (y1 - y0)/(x1 - x0)
		double slope = (static_cast&lt;double&gt;(fini.y) - static_cast&lt;double&gt;(ini.y)) / (static_cast&lt;double&gt;(fini.x) - static_cast&lt;double&gt;(ini.x) + 0.00001);

		//如果小于限制阈值，则去除
        //保存大于限制阈值的线
		if (std::abs(slope) &gt; slope_thresh) {
			slopes.push_back(slope);
			selected_lines.push_back(i);
		}
	}

	// 区分左右线
	img_center = static_cast&lt;double&gt;((img_edges.cols / 2));
	while (j &lt; selected_lines.size()) {
		ini = cv::Point(selected_lines[j][0], selected_lines[j][1]);
		fini = cv::Point(selected_lines[j][2], selected_lines[j][3]);

		// 如果斜率大于０且fini.x和fini大于图像中心点,则判断为左侧,反之右侧
		if (slopes[j] &gt; 0 &amp;&amp; fini.x &gt; img_center &amp;&amp; ini.x &gt; img_center) {
			right_lines.push_back(selected_lines[j]);
			right_flag = true;
		}
		else if (slopes[j] &lt; 0 &amp;&amp; fini.x &lt; img_center &amp;&amp; ini.x &lt; img_center) {
			left_lines.push_back(selected_lines[j]);
			left_flag = true;
		}
		j++;
	}

	output[0] = right_lines;
	output[1] = left_lines;

	return output;
}

//最终车道线选择
std::vector&lt;cv::Point&gt; LaneDetector::regression(std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; left_right_lines, cv::Mat inputImage) {
	std::vector&lt;cv::Point&gt; output(4);
	cv::Point ini;
	cv::Point fini;
	cv::Point ini2;
	cv::Point fini2;
	cv::Vec4d right_line;
	cv::Vec4d left_line;
	std::vector&lt;cv::Point&gt; right_pts;
	std::vector&lt;cv::Point&gt; left_pts;

	// 检测到右侧线，则把点给连上
	if (right_flag == true) {
		for (auto i : left_right_lines[0]) {
			ini = cv::Point(i[0], i[1]);
			fini = cv::Point(i[2], i[3]);

			right_pts.push_back(ini);
			right_pts.push_back(fini);
		}

		if (right_pts.size() &gt; 0) {
			//拟合
			cv::fitLine(right_pts, right_line, CV_DIST_L2, 0, 0.01, 0.01);
			right_m = right_line[1] / right_line[0];
			right_b = cv::Point(right_line[2], right_line[3]);
		}
	}

	// 检测到左侧线，则把点给连上
	if (left_flag == true) {
		for (auto j : left_right_lines[1]) {
			ini2 = cv::Point(j[0], j[1]);
			fini2 = cv::Point(j[2], j[3]);

			left_pts.push_back(ini2);
			left_pts.push_back(fini2);
		}

		if (left_pts.size() &gt; 0) {
			//拟合
			cv::fitLine(left_pts, left_line, CV_DIST_L2, 0, 0.01, 0.01);
			left_m = left_line[1] / left_line[0];
			left_b = cv::Point(left_line[2], left_line[3]);
		}
	}

	// 通过直线方程获得点
	int ini_y = inputImage.rows;
	int fin_y = 470;

	double right_ini_x = ((ini_y - right_b.y) / right_m) + right_b.x;
	double right_fin_x = ((fin_y - right_b.y) / right_m) + right_b.x;

	double left_ini_x = ((ini_y - left_b.y) / left_m) + left_b.x;
	double left_fin_x = ((fin_y - left_b.y) / left_m) + left_b.x;

	output[0] = cv::Point(right_ini_x, ini_y);
	output[1] = cv::Point(right_fin_x, fin_y);
	output[2] = cv::Point(left_ini_x, ini_y);
	output[3] = cv::Point(left_fin_x, fin_y);

	return output;
}


std::string LaneDetector::predictTurn() {
	std::string output;
	double vanish_x;
	double thr_vp = 10;

	//消失点:两直线交点
	vanish_x = static_cast&lt;double&gt;(((right_m*right_b.x) - (left_m*left_b.x) - right_b.y + left_b.y) / (right_m - left_m));

	//决策
	if (vanish_x &lt; (img_center - thr_vp))
		output = "Left Turn";
	else if (vanish_x &gt;(img_center + thr_vp))
		output = "Right Turn";
	else if (vanish_x &gt;= (img_center - thr_vp) &amp;&amp; vanish_x &lt;= (img_center + thr_vp))
		output = "Straight";

	return output;
}

int LaneDetector::plotLane(cv::Mat inputImage, std::vector&lt;cv::Point&gt; lane, std::string turn) 
{
	std::vector&lt;cv::Point&gt; poly_points;
	cv::Mat output;

	//渲染内部
	inputImage.copyTo(output);
	poly_points.push_back(lane[2]);
	poly_points.push_back(lane[0]);
	poly_points.push_back(lane[1]);
	poly_points.push_back(lane[3]);
	cv::fillConvexPoly(output, poly_points, cv::Scalar(0, 0, 255), CV_AA, 0);
	cv::addWeighted(output, 0.3, inputImage, 1.0 - 0.3, 0, inputImage);

	//划线
	cv::line(inputImage, lane[0], lane[1], cv::Scalar(0, 255, 255), 5, CV_AA);
	cv::line(inputImage, lane[2], lane[3], cv::Scalar(0, 255, 255), 5, CV_AA);

	// 决策信息
	cv::putText(inputImage, turn, cv::Point(50, 90), cv::FONT_HERSHEY_COMPLEX_SMALL, 3, cvScalar(0, 255, 0), 1, CV_AA);

	cv::namedWindow("Lane", CV_WINDOW_AUTOSIZE);
	cv::imshow("Lane", inputImage);
	return 0;
}
</code></pre>

<blockquote>
  <p>yolo_car_detect.h</p>
</blockquote>

<pre><code class="language-c++">/*
 * @Author: verylazycat 
 * @Date: 2020-04-17 14:28:03 
 * @Last Modified by: verylazycat
 * @Last Modified time: 2020-04-18 12:12:02
 */
#include &lt;opencv2/dnn.hpp&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
#include &lt;fstream&gt;
#include &lt;sstream&gt;
#include &lt;vector&gt;

using namespace cv;
using namespace dnn;
using namespace std;

//置信度
float confThreshold = 0.5;
float nmsThreshold = 0.4;

//图片输入尺寸
//参看cfg配置文件
int inpWidth = 416;  
int inpHeight = 416; 
//配置文件
const string classesFile = "../config/coco.names";
const string modelConfiguration = "../config/yolov3-tiny.cfg";
const string modelWeights = "../config/yolov3-tiny.weights";
//测试视频
cv::Mat img_denoise;
cv::Mat img_edges;
cv::Mat img_mask;
std::vector&lt;cv::Vec4i&gt; lines;
std::vector&lt;std::vector&lt;cv::Vec4i&gt; &gt; left_right_lines;
std::vector&lt;cv::Point&gt; lane;
std::string turn;
int flag_plot = -1;
int i = 0;
vector&lt;string&gt; classes;
// 删除置信度低的图片
void postprocess(Mat&amp; frame, const vector&lt;Mat&gt;&amp; out);

//画预测框
void drawPred(int classId, float conf, int left, int top, int right, int bottom, Mat&amp; frame);

//获取分类
vector&lt;String&gt; getOutputsNames(const Net&amp; net);

//config检测
size_t configFileDect()
{
	if(classesFile == NULL)
	{
		fprintf(stdout,"classesFile is NULL\n");
		return 1;
	}
	if(modelConfiguration == NULL)
	{
		perror("modelConfiguration");
		return 1;
	}
	if(modelWeights == NULL)
	{
		perror("modelWeights");
		return 1;
	}
}


//抑制低置信度
void postprocess(Mat&amp; frame, const vector&lt;Mat&gt;&amp; outs)
{
    vector&lt;int&gt; classIds;
    vector&lt;float&gt; confidences;
    vector&lt;Rect&gt; boxes;
    // 遍历每一个box
    for (size_t i = 0; i &lt; outs.size(); ++i)
    {
        float* data = (float*)outs[i].data;
        for (int j = 0; j &lt; outs[i].rows; ++j, data += outs[i].cols)
        {
            Mat scores = outs[i].row(j).colRange(5, outs[i].cols);
            Point classIdPoint;
            double confidence;
            //获取score最大和最小值
            minMaxLoc(scores, 0, &amp;confidence, 0, &amp;classIdPoint);
            if (confidence &gt; confThreshold)
            {
                int centerX = (int)(data[0] * frame.cols);
                int centerY = (int)(data[1] * frame.rows);
                int width = (int)(data[2] * frame.cols);
                int height = (int)(data[3] * frame.rows);
                int left = centerX - width / 2;
                int top = centerY - height / 2;
                
                classIds.push_back(classIdPoint.x);
                confidences.push_back((float)confidence);
                boxes.push_back(Rect(left, top, width, height));
            }
        }
    }
    
    vector&lt;int&gt; indices;
    NMSBoxes(boxes, confidences, confThreshold, nmsThreshold, indices);
    for (size_t i = 0; i &lt; indices.size(); ++i)
    {
        int idx = indices[i];
        Rect box = boxes[idx];
        drawPred(classIds[idx], confidences[idx], box.x, box.y,
                 box.x + box.width, box.y + box.height, frame);
    }
}

//绘画渲染
void drawPred(int classId, float conf, int left, int top, int right, int bottom, Mat&amp; frame)
{
    //矩形框
    rectangle(frame, Point(left, top), Point(right, bottom), Scalar(0, 255, 0), 3);
    
    //获取name和置信度
    string label = format("%.2f", conf);
    if (!classes.empty())
    {
        CV_Assert(classId &lt; (int)classes.size());
        label = classes[classId] + ":" + label;
    }
    //说明
    int baseLine;
    Size labelSize = getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, &amp;baseLine);
    top = max(top, labelSize.height);
    rectangle(frame, Point(left, top - round(1.5*labelSize.height)), Point(left + round(1.5*labelSize.width), top + baseLine), Scalar(255, 255, 255), FILLED);
    putText(frame, label, Point(left, top), FONT_HERSHEY_SIMPLEX, 0.75, Scalar(0,0,0),1);
}
//获取name
vector&lt;String&gt; getOutputsNames(const Net&amp; net)
{
    static vector&lt;String&gt; names;
    if (names.empty())
    {
        vector&lt;int&gt; outLayers = net.getUnconnectedOutLayers();
        //获取所有name
        vector&lt;String&gt; layersNames = net.getLayerNames();
        //获取当前的name
        names.resize(outLayers.size());
        for (size_t i = 0; i &lt; outLayers.size(); ++i)
        names[i] = layersNames[outLayers[i] - 1];
    }
    return names;
}
</code></pre>

<h1 id="安装使用">安装使用</h1>

<h2 id="opencv配置">opencv配置</h2>

<blockquote>
  <p>建议使用3.4.5版本,其中 dnn 模块支持较好.</p>
</blockquote>

<ul>
  <li>下载链接</li>
  <li>解压</li>
</ul>

<pre><code class="language-bash">unzip opencv- . . .zip
cd opencv- 3.4.5
</code></pre>

<ul>
  <li>安装cmake</li>
</ul>

<pre><code class="language-bash">sudo apt-get install cmake
</code></pre>

<ul>
  <li>依赖环境</li>
</ul>

<pre><code class="language-bash">sudo apt-get install build-essential libgtk . -dev libavcodec-dev libavformat-dev libjpeg-dev libswscale-
dev libtiff -dev
sudo apt-get install libgtk . -dev
sudo apt-get install pkg-config
</code></pre>

<ul>
  <li>建立build</li>
</ul>

<pre><code class="language-bash">mkdir build
cd build
</code></pre>

<ul>
  <li>cmake</li>
</ul>

<pre><code class="language-bash">sudo cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..
</code></pre>

<ul>
  <li>编译</li>
</ul>

<pre><code class="language-bash">sudo make -j8
</code></pre>

<ul>
  <li>安装</li>
</ul>

<pre><code class="language-bash">sudo make install
</code></pre>

<ul>
  <li>配置环境</li>
</ul>

<pre><code class="language-bash">sudo gedit /etc/ld.so.conf
#添加 /usr/loacal/lib
sudo gedit /etc/bash.bashrc
#在文件末尾加入:
#PKG_CONFIG_PATH=$PKG_CONFIG_PATH:/usr/local/lib/pkgconfig
#export PKG_CONFIG_PATH
source /etc/bash.bashrc
</code></pre>

<h2 id="dlib配置">Dlib配置</h2>

<ul>
  <li>安装libboost</li>
</ul>

<pre><code class="language-bash">sudo apt-get install libboost-all-dev
</code></pre>

<ul>
  <li>下载dlib</li>
</ul>

<pre><code class="language-bash">git clone https://github.com/davisking/dlib.git
</code></pre>

<ul>
  <li>build</li>
</ul>

<pre><code class="language-bash">cd dlib
mkdir build; cd build; cmake .. -DDLIB_USE_CUDA=0 -DUSE_AVX_INSTRUCTIONS=1; cmake --build .
</code></pre>

<blockquote>
  <p>-DDLIB_USE_CUDA=0 不使用cuda</p>
</blockquote>

<blockquote>
  <p>-DUSE_AVX_INSTRUCTIONS=1 使用cpu的AVX加速</p>
</blockquote>

<ul>
  <li>python扩展</li>
</ul>

<pre><code class="language-bash">cd ..
python setup.py install --yes USE_AVX_INSTRUCTIONS --no DLIB_USE_CUDA
</code></pre>

<h2 id="编译程序">编译程序</h2>

<h3 id="fatiguedrivingdetection">FatigueDrivingDetection</h3>

<pre><code class="language-bash">cd FatigueDrivingDetection
mkdir build
cd build/
cmake .. -DCMAKE_BUILD_TYPE=Release | tee ../log/cmake_log
make -j |tee ../log/make_log
chmod +x FatigueDrivingDe
</code></pre>

<h3 id="lane_car_detect-1">lane_car_detect</h3>

<pre><code class="language-bash">cd lane_car_detect/
mkdir build
cd build
cmake ..
make
chmod +x lane_car_detect
./lane_car_detect
</code></pre>


</div>
<div class="v">
  <i class="fas fa-spinner fa-pulse"></i>
</div>
<script
  src='https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js'
  defer='defer'
  onload='
    new Valine({
      "el": document.getElementsByClassName("v")[0],
      "appId": "9hABRddSuEkTgqLrt1VSK5B1-gzGzoHsz",
      "appKey": "NJ7RwmgrxsF7KDzlqU7YewlL",
      "placeholder": "在这里评论吧！填写邮箱可以获得 Gravatar 头像和回复通知哦",
      "requiredFields": ["nick","mail"],
      "visitor": true,
      "recordIP": true
    })'
></script>

</div>
  </div>
  
  <label for="sidebar-checkbox" class="sidebar-toggle"></label>
  
</body>

</html>